"""ReAct ì—ì´ì „íŠ¸ êµ¬í˜„"""

from datetime import date, datetime
from typing import Dict, List, Optional, Union

import pytz
from langchain_core.messages import (
    AIMessage,
    HumanMessage,
    SystemMessage,
    ToolMessage,
)
from langchain_google_genai import ChatGoogleGenerativeAI
from langgraph.graph import END, StateGraph
from langgraph.prebuilt import ToolNode
from langsmith import traceable

from app.agent.prompt import (
    create_date_prompt,
    create_execute_tool_prompt,
    create_final_report_prompt,
    create_health_analyze_prompt,
    create_planner_prompt,
)
from app.agent.state import (
    AgentState,
    AnalysisPlan,
    DateRange,
    HealthAnalysisResult,
    determine_date_type_and_origin,
    save_analysis_result,
)
from app.agent.tool import (
    ActivitySummaryTool,
    HeartRateSummaryTool,
    HeartRateTimeSeriesTool,
    SleepSummaryTool,
    SleepTimeSeriesTool,
    StepsSummaryTool,
    StepsTimeSeriesTool,
    StressSummaryTool,
    StressTimeSeriesTool,
)
from core.config import GEMINI_API_KEY


class HealthAnalysisAgent:
    """ê±´ê°• ë°ì´í„° ë¶„ì„ ì—ì´ì „íŠ¸"""

    def __init__(self):
        self.tools = self._initialize_tools()
        self.graph = self._create_graph()

    def _initialize_tools(self):
        """ë„êµ¬ ì´ˆê¸°í™”"""
        return [
            # ì‹¬ë°•ìˆ˜ ë„êµ¬
            HeartRateSummaryTool(),
            HeartRateTimeSeriesTool(),
            # ê±¸ìŒìˆ˜ ë„êµ¬
            StepsSummaryTool(),
            StepsTimeSeriesTool(),
            # ìŠ¤íŠ¸ë ˆìŠ¤ ë„êµ¬
            StressSummaryTool(),
            StressTimeSeriesTool(),
            # ìˆ˜ë©´ ë„êµ¬
            SleepSummaryTool(),
            SleepTimeSeriesTool(),
            # í™œë™ ë„êµ¬
            ActivitySummaryTool(),
        ]

    def _extract_tool_metadata(self):
        """ë„êµ¬ ë¦¬ìŠ¤íŠ¸ì—ì„œ name, description, parameters ì¶”ì¶œ"""
        tools_info = []

        for tool in self.tools:
            tool_info = {
                "name": tool.name,
                "description": tool.description,
                "parameters": list(tool.args_schema.__annotations__.keys()),
            }
            tools_info.append(tool_info)

        return tools_info

    def _initialize_llm(
        self, temperature: float = 0.8, model_name: str = "gemini-2.0-flash"
    ):
        """LLM ì´ˆê¸°í™”"""
        model = ChatGoogleGenerativeAI(
            model=model_name,
            google_api_key=GEMINI_API_KEY,
            temperature=temperature,
        )
        return model

    def _adjust_date_range(
        self, start_date_str: str, end_date_str: str, today_date: date
    ) -> DateRange:
        """LLMì—ì„œ ì¶”ì¶œëœ ë‚ ì§œ ë¬¸ìì—´ì„ íŒŒì‹±í•˜ê³  ì˜¤ëŠ˜ ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ ì¡°ì •í•©ë‹ˆë‹¤."""
        try:
            start_date = datetime.strptime(start_date_str, "%Y-%m-%d").date()
            end_date = datetime.strptime(end_date_str, "%Y-%m-%d").date()
        except ValueError:
            start_date = today_date
            end_date = today_date

        adjusted_start_date = min(start_date, today_date)
        adjusted_end_date = min(end_date, today_date)

        if adjusted_start_date > adjusted_end_date:
            adjusted_start_date = adjusted_end_date

        return DateRange(
            start_date=adjusted_start_date.strftime("%Y-%m-%d"),
            end_date=adjusted_end_date.strftime("%Y-%m-%d"),
        )

    def _extract_analysis_dates(self, state: AgentState):
        """ì‚¬ìš©ì ì¿¼ë¦¬ì—ì„œ ë¶„ì„í•  ë‚ ì§œ ë²”ìœ„ë¥¼ ì¶”ì¶œ"""
        detail_params = state.get("detail_params", {})
        user_query = state["user_query"]
        today_date = state["today"]
        date_type, origin = determine_date_type_and_origin(detail_params, user_query)

        date_llm = self._initialize_llm().with_structured_output(DateRange)
        prompt = create_date_prompt().invoke(
            {
                "today": today_date.strftime("%Y-%m-%d"),
                "query": origin,
                "date_type": date_type,
            }
        )
        dates_output: DateRange = date_llm.invoke(prompt)
        adjusted_dates = self._adjust_date_range(
            dates_output.start_date, dates_output.end_date, today_date
        )
        return adjusted_dates

    def _generate_analysis_plan(self, state: AgentState, date_range: DateRange):
        """ì¶”ì¶œëœ ë‚ ì§œ ë²”ìœ„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„ ê³„íšì„ ìƒì„±"""
        planner_llm = self._initialize_llm(
            model_name="gemini-1.5-pro"
        ).with_structured_output(AnalysisPlan)
        date_message = SystemMessage(
            content=f"ì˜¤ëŠ˜ ë‚ ì§œëŠ” {state['today'].strftime('%Y-%m-%d')}ì…ë‹ˆë‹¤.\në¶„ì„í•´ì•¼ í•  ê¸°ê°„ì€ {date_range.start_date}ë¶€í„° {date_range.end_date}ê¹Œì§€ì…ë‹ˆë‹¤."
        )
        planner_message = [
            create_planner_prompt(),
            date_message,
            HumanMessage(content=state["user_query"]),
        ]
        return planner_llm.invoke(planner_message)

    def _create_plan_node(self):
        """ì‚¬ìš©ì ì§ˆë¬¸ì— ë”°ë¥¸ ë¶„ì„ ê¸°ê°„ê³¼ ê³„íš ìƒì„±"""

        def plan_processor(state: AgentState):
            date_range_output: DateRange = self._extract_analysis_dates(state)
            response = self._generate_analysis_plan(state, date_range_output)
            return {
                "analysis_plan": response.analysis_plan,
                "focus_areas": response.focus_areas,
                "user_intent": response.user_intent,
            }

        return plan_processor

    def _format_tool_execution_message(self, state: AgentState):
        """ë¶„ì„ ê³„íšê³¼ ì¶”ê°€ ë¶„ì„ ìš”ì²­ì„ ê¸°ë°˜ìœ¼ë¡œ ì‹¤í–‰ ë©”ì‹œì§€ ìƒì„±"""
        last_analysis = (
            state["analysis_history"][-1] if state["analysis_history"] else None
        )

        additional_analysis_targets = (
            ", ".join(last_analysis.additional_analysis_targets)
            if last_analysis and last_analysis.additional_analysis_targets
            else "ì—†ìŒ"
        )
        analysis_plan_string = "\n".join(
            [f"- {plan}" for plan in state["analysis_plan"]]
        )

        messages = [
            HumanMessage(
                content=f"ì˜¤ëŠ˜ ë‚ ì§œëŠ” {state['today'].strftime('%Y-%m-%d')}ì…ë‹ˆë‹¤.\n ì‚¬ìš©ì ì•„ì´ë”” {state['user_id']}ì˜ ë¶„ì„ ê³„íš:\n{analysis_plan_string}"
            )
        ]

        if last_analysis and last_analysis.additional_analysis_targets:
            messages.append(
                HumanMessage(
                    content=f"ì¶”ê°€ ë¶„ì„ì´ í•„ìš”í•œ ê²½ìš°, ì¡°íšŒí•  ë°ì´í„° ëª©ë¡: {additional_analysis_targets}"
                )
            )

        return messages

    def _select_tools_to_execute(self, state: AgentState, messages):
        """AIì—ê²Œ ì ì ˆí•œ ë„êµ¬ ì‹¤í–‰ì„ ìš”ì²­"""

        tools_selection_llm = self._initialize_llm().bind_tools(
            self.tools, tool_choice=True
        )
        tools_info = self._extract_tool_metadata()
        system_message = create_execute_tool_prompt(tools_info, state["tool_history"])
        valid_messages = [m for m in messages if m is not None]
        return tools_selection_llm.invoke([system_message] + valid_messages)

    def _create_execute_tool_node(self):
        """ê³„íšê³¼ ì‹¤í–‰ ì´ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ ë„êµ¬ë¥¼ ì‹¤í–‰í•˜ëŠ” ë…¸ë“œ"""

        def execute_tool(state: AgentState):
            messages = self._format_tool_execution_message(state)
            response = self._select_tools_to_execute(state, messages)
            return {"messages": state["messages"] + [response]}

        return execute_tool

    def _extract_tool_execution_results(self, state: AgentState):
        """ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ ìˆ˜ì§‘í•˜ì—¬ ì •ë¦¬"""
        tool_messages = []
        tool_calls = []
        for message in reversed(state["messages"]):
            if isinstance(message, AIMessage) and message.content != "":
                break
            if isinstance(message, ToolMessage):
                tool_messages.append(message)
            if isinstance(message, AIMessage) and message.content == "":
                tool_calls = message.tool_calls

        for tool_call in tool_calls:
            tool_call_id = tool_call.get("id") if isinstance(tool_call, dict) else None
            if tool_call_id:
                tool_result = next(
                    (
                        msg.status
                        for msg in tool_messages
                        if msg.tool_call_id == tool_call_id
                    ),
                    "error",
                )
                state["tool_history"].append(
                    {
                        "name": tool_call.get("name", "unknown"),
                        "arguments": tool_call.get("args", {}),
                        "status": tool_result,
                    }
                )

        return [msg.content for msg in tool_messages]

    def _process_analysis_history(
        self, analysis_history: List[HealthAnalysisResult], comment_length=1000
    ) -> List[Dict[str, Union[str, List[str]]]]:
        """ë¶„ì„ ì´ë ¥ì„ ì²˜ë¦¬í•˜ì—¬ ìš”ì•½ê³¼ í•´ë‹¹ ì¸ì‚¬ì´íŠ¸ë¥¼ ê·¸ë£¹í™”í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.

        Args:
            analysis_history: ë¶„ì„ ì´ë ¥ ëª©ë¡ (HealthAnalysisResult ê°ì²´ ë¦¬ìŠ¤íŠ¸)
            comment_length: ê° ì½”ë©˜íŠ¸ ìµœëŒ€ ê¸¸ì´

        Returns:
            List[Dict[str, Union[str, List[str]]]]: ê° ë¶„ì„ ê²°ê³¼ì˜ ìš”ì•½ê³¼ ì¸ì‚¬ì´íŠ¸ ëª©ë¡ì„ ë‹´ì€ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
            ì˜ˆ: [{'summary': 'ìš”ì•½1', 'insights': ['ì¸ì‚¬ì´íŠ¸1-1', 'ì¸ì‚¬ì´íŠ¸1-2']}, {'summary': 'ìš”ì•½2', 'insights': ['ì¸ì‚¬ì´íŠ¸2-1']}]
        """
        if not analysis_history:
            return []

        processed_history = []

        for result in analysis_history:
            current_summary = (
                result.summary if result.summary else "ìš”ì•½ ì—†ìŒ"
            )  # Handle None summary
            current_insights = []
            for insight in result.insights:
                if not insight.comment:
                    continue

                comment = (
                    insight.comment[: comment_length - 3] + "..."
                    if len(insight.comment) > comment_length
                    else insight.comment
                )
                current_insights.append(comment)

            processed_history.append(
                {"summary": current_summary, "insights": current_insights}
            )

        return processed_history

    def _format_analysis_history_for_prompt(
        self, processed_history: List[Dict[str, Union[str, List[str]]]]
    ) -> str:
        """ì²˜ë¦¬ëœ ë¶„ì„ ê¸°ë¡ì„ _generate_analysis í”„ë¡¬í”„íŠ¸ìš© ë¬¸ìì—´ë¡œ í¬ë§·íŒ…í•©ë‹ˆë‹¤."""
        if not processed_history:
            return "ì´ì „ ë¶„ì„ ê²°ê³¼ ì—†ìŒ."

        analysis_parts = []
        for i, history_item in enumerate(processed_history):
            summary_part = f"ì´ì „ ë¶„ì„ ê²°ê³¼ {i+1}:\n{history_item['summary']}"
            insights_part = ""
            if history_item["insights"]:
                insights_list_str = "\n".join(
                    [f"- {insight}" for insight in history_item["insights"]]
                )
                insights_part = f"\nì£¼ìš” ì¸ì‚¬ì´íŠ¸:\n{insights_list_str}"
            analysis_parts.append(summary_part + insights_part)

        return "\n\n".join(analysis_parts)

    def _generate_analysis(self, state: AgentState, parsed_tool_data):
        """AIì—ê²Œ ê±´ê°• ë°ì´í„° ë¶„ì„ ìš”ì²­"""
        analyze_health_llm = self._initialize_llm().with_structured_output(
            HealthAnalysisResult
        )
        system_message = create_health_analyze_prompt(self._extract_tool_metadata())
        human_message = HumanMessage(content=f"ë„êµ¬ ì‹¤í–‰ ê²°ê³¼: {parsed_tool_data}")

        processed_history = self._process_analysis_history(
            state.get("analysis_history", [])
        )
        previous_analysis_content = self._format_analysis_history_for_prompt(
            processed_history
        )

        plan_items = [
            f"- {plan}" for plan in state.get("analysis_plan", [])
        ]  # None ëŒ€ì‹  ë¹ˆ ë¦¬ìŠ¤íŠ¸ ì‚¬ìš©
        analysis_plan = """
        ë¶„ì„ ê³„íš:
        """ + "\n".join(
            plan_items
        )

        previous_analysis_message = SystemMessage(
            content=f"""
            {analysis_plan}

            ì´ì „ ë¶„ì„ ê²°ê³¼ë¥¼ ê³ ë ¤í•˜ì—¬ ìƒˆë¡œìš´ ê±´ê°• ë¶„ì„ì„ ìˆ˜í–‰í•˜ì„¸ìš”.

            {previous_analysis_content}
            """
        )
        response = analyze_health_llm.invoke(
            [system_message, human_message, previous_analysis_message]
        )

        if response is None:
            raise ValueError("Health analysis model returned None!")

        return response

    def _create_analysis_node(self):
        """ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ê³  ì¶”ê°€ ë¶„ì„ ì—¬ë¶€ë¥¼ íŒë‹¨í•˜ëŠ” ë…¸ë“œ"""

        def analysis(state: AgentState):
            parsed_tool_data = self._extract_tool_execution_results(state)
            response = self._generate_analysis(state, parsed_tool_data)
            if response is None or response.summary is None:
                raise ValueError(
                    "Health analysis response is invalid or missing a summary."
                )
            save_analysis_result(state, response)
            return {
                "messages": state["messages"] + [AIMessage(content=response.summary)],
                "loop_count": state.get("loop_count", 0) + 1,
            }

        return analysis

    def _create_report_node(self):
        """ë¶„ì„ ë…¸ë“œì˜ ê²°ê³¼ë¥¼ ìµœì¢… ë³´ê³ ì„œë¡œ ë³€í™˜í•˜ëŠ” ë…¸ë“œ (ìˆ˜ì •ë¨)"""
        report_llm = self._initialize_llm(
            model_name="gemini-2.0-flash-thinking-exp-01-21"
        )

        def report(state: AgentState):
            processed_history = self._process_analysis_history(
                state.get("analysis_history", [])
            )

            all_summaries = [
                item.get("summary", "ìš”ì•½ ì—†ìŒ") for item in processed_history
            ]
            joined_summaries = " ".join(all_summaries)

            all_insights = [
                insight
                for item in processed_history
                for insight in item.get("insights", [])
            ]
            joined_insights = "- " + "\n- ".join(all_insights)

            focus_areas_str = ", ".join(state.get("focus_areas", ["ê±´ê°•"]))
            user_intent = state.get(
                "user_intent", "ìµœê·¼ ê±´ê°• ìƒíƒœê°€ ì–´ë–¤ì§€ ì•Œê³  ì‹¶ì–´í•©ë‹ˆë‹¤."
            )

            report_prompt_message = HumanMessage(
                content=f"""
                # ğŸ¥ ({focus_areas_str} ì¤‘ ì‚¬ìš©ì ì§ˆë¬¸ ì˜ë„ì— ë§ëŠ” ë‹¨ì–´) ë¶„ì„ ë³´ê³ ì„œ

                ## ğŸ™‹ ì‚¬ìš©ì ì§ˆë¬¸ ì˜ë„
                {user_intent}

                # ğŸ“Œ ìš”ì•½
                {joined_summaries if joined_summaries else 'ì¢…í•©ì ì¸ ìš”ì•½ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.'}

                # ğŸ” ì£¼ìš” ì¸ì‚¬ì´íŠ¸
                {joined_insights if all_insights else 'íŠ¹ë³„í•œ ì¸ì‚¬ì´íŠ¸ê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'}

                ìœ„ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê±´ê°• í”¼ë“œë°±ê³¼ ê°œì„  ë°©ì•ˆì„ Markdown í˜•ì‹ìœ¼ë¡œ ë³´ê³ ì„œë§Œ ì‘ì„±í•˜ì„¸ìš”.
                """
            )
            response = report_llm.invoke(
                [create_final_report_prompt(), report_prompt_message]
            )

            return {
                "messages": state.get("messages", []) + [response],
                "final_report": response.content,
            }

        return report

    def _create_graph(self):
        """ê·¸ë˜í”„ ìƒì„±"""

        tools_node = ToolNode(tools=self.tools)
        plan_node_title = "plan"
        execute_tool_node_title = "execute_tool"
        analysis_node_title = "analysis"
        report_node_title = "report"
        tools_node_title = "tools"

        # ê·¸ë˜í”„ ìƒì„±
        workflow = StateGraph(AgentState)

        def custom_tool_condition(state: AgentState):
            """ë„êµ¬ ì„ íƒ ì¡°ê±´"""
            last_analysis = (
                state["analysis_history"][-1] if state["analysis_history"] else None
            )

            if state.get("loop_count", 0) >= 7:
                return "ë¦¬í¬íŠ¸ ìƒì„±"

            return (
                "ì¶”ê°€ ë¶„ì„ ìš”ì²­"
                if last_analysis and last_analysis.additional_analysis_needed
                else "ë¦¬í¬íŠ¸ ìƒì„±"
            )

        # ë…¸ë“œ ì¶”ê°€
        workflow.add_node(plan_node_title, self._create_plan_node())
        workflow.add_node(analysis_node_title, self._create_analysis_node())
        workflow.add_node(execute_tool_node_title, self._create_execute_tool_node())
        workflow.add_node(report_node_title, self._create_report_node())
        workflow.add_node(tools_node_title, tools_node)

        # ì—£ì§€ ì¶”ê°€
        workflow.set_entry_point(plan_node_title)
        workflow.add_edge(plan_node_title, execute_tool_node_title)
        workflow.add_edge(execute_tool_node_title, tools_node_title)
        workflow.add_edge(tools_node_title, analysis_node_title)
        workflow.add_edge(report_node_title, END)

        # ì¡°ê±´ ì—£ì§€ ì¶”ê°€
        workflow.add_conditional_edges(
            analysis_node_title,
            custom_tool_condition,
            {
                "ì¶”ê°€ ë¶„ì„ ìš”ì²­": execute_tool_node_title,
                "ë¦¬í¬íŠ¸ ìƒì„±": report_node_title,
            },
        )

        return workflow.compile()

    def create_initial_state(
        self,
        detail_params: dict,
        query: str,
        user_id: int,
        user_timezone: Optional[str] = None,
    ) -> dict:
        """ì´ˆê¸° ìƒíƒœ ìƒì„±"""
        timezone = pytz.timezone(user_timezone) if user_timezone else pytz.utc
        today = datetime.now(timezone).date()

        return {
            "user_query": query,
            "user_id": user_id,
            "user_timezone": user_timezone,
            "today": today,
            "tool_history": [],
            "analysis_history": [],
            "loop_count": 0,
            "final_report": "",
            "detail_params": detail_params,
        }

    @traceable
    def run(
        self,
        query: str,
        user_id: int,
        detail_params: dict,
        user_timezone: Optional[str] = None,
    ):
        """ì—ì´ì „íŠ¸ ì‹¤í–‰"""
        try:
            initial_state = self.create_initial_state(
                query=query,
                user_id=user_id,
                user_timezone=user_timezone,
                detail_params=detail_params,
            )

            graph = self._create_graph()
            final_result = graph.invoke(initial_state)

            return final_result
        except Exception as e:
            raise Exception(f"ì—ëŸ¬ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

    def visualize_graph(self, output_path="graph_visualization.png"):
        """ê·¸ë˜í”„ë¥¼ ì‹œê°í™”í•˜ê³  íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.

        Args:
            output_path (str): ì €ì¥í•  íŒŒì¼ ê²½ë¡œ

        Returns:
            bool: ì„±ê³µ ì—¬ë¶€
        """
        try:
            graph = self._create_graph()

            graph_image = graph.get_graph().draw_mermaid_png()
            with open(output_path, "wb") as f:
                f.write(graph_image)
            print(f"ê·¸ë˜í”„ ì‹œê°í™”ê°€ '{output_path}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            return True
        except Exception as e:
            print(f"ê·¸ë˜í”„ ì‹œê°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return False


def create_agent() -> HealthAnalysisAgent:
    """ê±´ê°• ë¶„ì„ ì—ì´ì „íŠ¸ ìƒì„±

    Returns:
        HealthAnalysisAgent: ì´ˆê¸°í™”ëœ ê±´ê°• ë¶„ì„ ì—ì´ì „íŠ¸
    """
    return HealthAnalysisAgent()
