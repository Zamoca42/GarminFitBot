"""ReAct ì—ì´ì „íŠ¸ êµ¬í˜„"""

from datetime import datetime
from typing import Optional

import pytz
from langchain_core.messages import (
    AIMessage,
    HumanMessage,
    SystemMessage,
    ToolMessage,
)
from langchain_google_genai import ChatGoogleGenerativeAI
from langgraph.graph import END, StateGraph
from langgraph.prebuilt import ToolNode
from langsmith import traceable

from app.agent.prompt import (
    create_date_prompt,
    create_execute_tool_prompt,
    create_final_report_prompt,
    create_health_analyze_prompt,
    create_planner_prompt,
)
from app.agent.state import (
    AgentState,
    AnalysisPlan,
    DateRange,
    HealthAnalysisResult,
    save_analysis_result,
)
from app.agent.tool import (
    ActivitySummaryTool,
    HeartRateSummaryTool,
    HeartRateTimeSeriesTool,
    SleepSummaryTool,
    SleepTimeSeriesTool,
    StepsSummaryTool,
    StepsTimeSeriesTool,
    StressSummaryTool,
    StressTimeSeriesTool,
)
from core.config import GEMINI_API_KEY


class HealthAnalysisAgent:
    """ê±´ê°• ë°ì´í„° ë¶„ì„ ì—ì´ì „íŠ¸"""

    def __init__(self):
        self.tools = self._initialize_tools()
        self.graph = self._create_graph()

    def _initialize_tools(self):
        """ë„êµ¬ ì´ˆê¸°í™”"""
        return [
            # ì‹¬ë°•ìˆ˜ ë„êµ¬
            HeartRateSummaryTool(),
            HeartRateTimeSeriesTool(),
            # ê±¸ìŒìˆ˜ ë„êµ¬
            StepsSummaryTool(),
            StepsTimeSeriesTool(),
            # ìŠ¤íŠ¸ë ˆìŠ¤ ë„êµ¬
            StressSummaryTool(),
            StressTimeSeriesTool(),
            # ìˆ˜ë©´ ë„êµ¬
            SleepSummaryTool(),
            SleepTimeSeriesTool(),
            # í™œë™ ë„êµ¬
            ActivitySummaryTool(),
        ]

    def _extract_tool_metadata(self):
        """ë„êµ¬ ë¦¬ìŠ¤íŠ¸ì—ì„œ name, description, parameters ì¶”ì¶œ"""
        tools_info = []

        for tool in self.tools:
            tool_info = {
                "name": tool.name,
                "description": tool.description,
                "parameters": list(tool.args_schema.__annotations__.keys()),
            }
            tools_info.append(tool_info)

        return tools_info

    def _initialize_llm(self, temperature: float = 0.8):
        """LLM ì´ˆê¸°í™”"""
        model = ChatGoogleGenerativeAI(
            model="gemini-2.0-flash",
            google_api_key=GEMINI_API_KEY,
            temperature=temperature,
        )
        return model

    def _extract_analysis_dates(self, state: AgentState):
        """ì‚¬ìš©ì ì¿¼ë¦¬ì—ì„œ ë¶„ì„í•  ë‚ ì§œ ë²”ìœ„ë¥¼ ì¶”ì¶œ"""
        date_llm = self._initialize_llm(temperature=0).with_structured_output(DateRange)
        dates = create_date_prompt().invoke(
            {
                "today": state["today"].strftime("%Y-%m-%d"),
                "query": state["user_query"],
            }
        )
        return date_llm.invoke(dates)

    def _generate_analysis_plan(self, state: AgentState, start_date, end_date):
        """ì¶”ì¶œëœ ë‚ ì§œ ë²”ìœ„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„ ê³„íšì„ ìƒì„±"""
        planner_llm = self._initialize_llm().with_structured_output(AnalysisPlan)
        date_message = SystemMessage(
            content=f"ì˜¤ëŠ˜ ë‚ ì§œëŠ” {state['today'].strftime('%Y-%m-%d')}ì…ë‹ˆë‹¤. ë¶„ì„í•´ì•¼ í•  ê¸°ê°„ì€ {start_date}ë¶€í„° {end_date}ê¹Œì§€ì…ë‹ˆë‹¤."
        )
        planner_message = [
            create_planner_prompt(),
            date_message,
            HumanMessage(content=state["user_query"]),
        ]
        return planner_llm.invoke(planner_message)

    def _create_plan_node(self):
        """ì‚¬ìš©ì ì§ˆë¬¸ì— ë”°ë¥¸ ë¶„ì„ ê¸°ê°„ê³¼ ê³„íš ìƒì„±"""

        def plan_processor(state: AgentState):
            output = self._extract_analysis_dates(state)
            start_date = datetime.strptime(output.start_date, "%Y-%m-%d").date()
            end_date = datetime.strptime(output.end_date, "%Y-%m-%d").date()
            response = self._generate_analysis_plan(state, start_date, end_date)
            return {
                "analysis_plan": response.analysis_plan,
                "start_date": start_date,
                "end_date": end_date,
            }

        return plan_processor

    def _format_tool_execution_message(self, state: AgentState):
        """ë¶„ì„ ê³„íšê³¼ ì¶”ê°€ ë¶„ì„ ìš”ì²­ì„ ê¸°ë°˜ìœ¼ë¡œ ì‹¤í–‰ ë©”ì‹œì§€ ìƒì„±"""
        last_analysis = (
            state["analysis_history"][-1] if state["analysis_history"] else None
        )

        additional_analysis_targets = (
            ", ".join(last_analysis.additional_analysis_targets)
            if last_analysis and last_analysis.additional_analysis_targets
            else "ì—†ìŒ"
        )
        analysis_plan_string = "\n".join(
            [f"- {plan}" for plan in state["analysis_plan"]]
        )

        messages = [
            HumanMessage(
                content=f"ì‚¬ìš©ì ì•„ì´ë”” {state['user_id']}ì˜ ë¶„ì„ ê³„íš:\n{analysis_plan_string}"
            )
        ]

        if last_analysis and last_analysis.additional_analysis_targets:
            messages.append(
                HumanMessage(
                    content=f"ì¶”ê°€ ë¶„ì„ì´ í•„ìš”í•œ ê²½ìš°, ì¡°íšŒí•  ë°ì´í„° ëª©ë¡: {additional_analysis_targets}"
                )
            )

        return messages

    def _select_tools_to_execute(self, state: AgentState, messages):
        """AIì—ê²Œ ì ì ˆí•œ ë„êµ¬ ì‹¤í–‰ì„ ìš”ì²­"""

        tools_selection_llm = self._initialize_llm().bind_tools(
            self.tools, tool_choice=True
        )
        tools_info = self._extract_tool_metadata()
        system_message = create_execute_tool_prompt(
            tools_info, state["user_id"], state["tool_history"]
        )
        valid_messages = [m for m in messages if m is not None]
        return tools_selection_llm.invoke([system_message] + valid_messages)

    def _create_execute_tool_node(self):
        """ê³„íšê³¼ ì‹¤í–‰ ì´ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ ë„êµ¬ë¥¼ ì‹¤í–‰í•˜ëŠ” ë…¸ë“œ"""

        def execute_tool(state: AgentState):
            messages = self._format_tool_execution_message(state)
            response = self._select_tools_to_execute(state, messages)
            return {"messages": state["messages"] + [response]}

        return execute_tool

    def _extract_tool_execution_results(self, state: AgentState):
        """ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ ìˆ˜ì§‘í•˜ì—¬ ì •ë¦¬"""
        tool_messages = []
        tool_calls = []
        for message in reversed(state["messages"]):
            if isinstance(message, AIMessage) and message.content != "":
                break
            if isinstance(message, ToolMessage):
                tool_messages.append(message)
            if isinstance(message, AIMessage) and message.content == "":
                tool_calls = message.tool_calls

        for tool_call in tool_calls:
            tool_result = next(
                (
                    msg.status
                    for msg in tool_messages
                    if msg.tool_call_id == tool_call["id"]
                ),
                "error",
            )
            state["tool_history"].append(
                {
                    "name": tool_call["name"],
                    "arguments": tool_call["args"],
                    "status": tool_result,
                }
            )

        return [msg.content for msg in tool_messages]

    def _generate_health_analysis(self, state: AgentState, parsed_tool_data):
        """AIì—ê²Œ ê±´ê°• ë¶„ì„ ìš”ì²­"""
        analyze_health_llm = self._initialize_llm().with_structured_output(
            HealthAnalysisResult
        )
        system_message = create_health_analyze_prompt()
        human_message = HumanMessage(content=f"ë„êµ¬ ì‹¤í–‰ ê²°ê³¼: {parsed_tool_data}")

        previous_analysis_summaries = (
            "\n\n".join(
                [
                    f"ì´ì „ ë¶„ì„ ê²°ê³¼ {i+1}:\n{history.summary}\n\nì£¼ìš” ì¸ì‚¬ì´íŠ¸:\n- "
                    + "\n- ".join(history.insights)
                    for i, history in enumerate(state["analysis_history"][-5:])
                ]
            )
            if state["analysis_history"]
            else "ì´ì „ ë¶„ì„ ê²°ê³¼ ì—†ìŒ."
        )

        previous_analysis_message = SystemMessage(
            content=f"{previous_analysis_summaries}\n\nìœ„ ë¶„ì„ ê²°ê³¼ë¥¼ ê³ ë ¤í•˜ì—¬ ìƒˆë¡œìš´ ê±´ê°• ë¶„ì„ì„ ìˆ˜í–‰í•˜ì„¸ìš”."
        )
        response = analyze_health_llm.invoke(
            [system_message, human_message, previous_analysis_message]
        )

        if response is None:
            raise ValueError("Health analysis model returned None!")

        return response

    def _create_analyze_health_node(self):
        """ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ê³  ì¶”ê°€ ë¶„ì„ ì—¬ë¶€ë¥¼ íŒë‹¨í•˜ëŠ” ë…¸ë“œ"""

        def analyze_health(state: AgentState):
            parsed_tool_data = self._extract_tool_execution_results(state)
            response = self._generate_health_analysis(state, parsed_tool_data)
            if response is None or response.summary is None:
                raise ValueError(
                    "Health analysis response is invalid or missing a summary."
                )
            save_analysis_result(state, response)
            return {
                "messages": state["messages"] + [AIMessage(content=response.summary)]
            }

        return analyze_health

    def _create_final_report_node(self):
        """ë¶„ì„ ë…¸ë“œì˜ ê²°ê³¼ë¥¼ ìµœì¢… ë³´ê³ ì„œë¡œ ë³€í™˜í•˜ëŠ” ë…¸ë“œ"""
        llm = self._initialize_llm()

        def final_report(state: AgentState):
            past_summaries = [history.summary for history in state["analysis_history"]]

            past_insights = []
            for history in state["analysis_history"]:
                past_insights.extend(history.insights)

            joined_summaries = " ".join(past_summaries)
            joined_insights = "- " + "\n- ".join(past_insights)

            human_message = HumanMessage(
                content=f"""
            # ğŸ“Œ ìš”ì•½
            {joined_summaries}

            # ğŸ” ì£¼ìš” ì¸ì‚¬ì´íŠ¸
            - {joined_insights}

            ìœ„ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê±´ê°• í”¼ë“œë°±ê³¼ ê°œì„  ë°©ì•ˆì„ Markdown í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
            """
            )
            response = llm.invoke([create_final_report_prompt(), human_message])

            return {
                "messages": state["messages"] + [response],
            }

        return final_report

    def _create_graph(self):
        """ê·¸ë˜í”„ ìƒì„±"""

        tools_node = ToolNode(tools=self.tools)
        plan_node_title = "plan"
        execute_tool_node_title = "execute_tool"
        analyze_health_node_title = "analyze_health"
        final_report_node_title = "final_report"
        tools_node_title = "tools"

        # ê·¸ë˜í”„ ìƒì„±
        workflow = StateGraph(AgentState)

        def custom_tool_condition(state: AgentState):
            """ë„êµ¬ ì„ íƒ ì¡°ê±´"""
            last_analysis = (
                state["analysis_history"][-1] if state["analysis_history"] else None
            )

            return (
                execute_tool_node_title
                if last_analysis and last_analysis.additional_analysis_needed
                else final_report_node_title
            )

        # ë…¸ë“œ ì¶”ê°€
        workflow.add_node(plan_node_title, self._create_plan_node())
        workflow.add_node(analyze_health_node_title, self._create_analyze_health_node())
        workflow.add_node(execute_tool_node_title, self._create_execute_tool_node())
        workflow.add_node(final_report_node_title, self._create_final_report_node())
        workflow.add_node(tools_node_title, tools_node)

        # ì—£ì§€ ì¶”ê°€
        workflow.set_entry_point(plan_node_title)
        workflow.add_edge(plan_node_title, execute_tool_node_title)
        workflow.add_edge(execute_tool_node_title, tools_node_title)
        workflow.add_edge(tools_node_title, analyze_health_node_title)
        workflow.add_edge(final_report_node_title, END)

        # ì¡°ê±´ ì—£ì§€ ì¶”ê°€
        workflow.add_conditional_edges(analyze_health_node_title, custom_tool_condition)

        return workflow.compile()

    def create_initial_state(
        self,
        query: str,
        user_id: int,
        user_timezone: Optional[str] = None,
    ) -> dict:
        """ì´ˆê¸° ìƒíƒœ ìƒì„±"""
        timezone = pytz.timezone(user_timezone) if user_timezone else pytz.utc
        today = datetime.now(timezone).date()

        return {
            "user_query": query,
            "user_id": user_id,
            "user_timezone": user_timezone,
            "today": today,
            "tool_history": [],
            "analysis_history": [],
        }

    @traceable
    def run(
        self,
        query: str,
        user_id: int,
        user_timezone: Optional[str] = None,
    ):
        """ì—ì´ì „íŠ¸ ì‹¤í–‰"""
        try:
            initial_state = self.create_initial_state(
                query=query,
                user_id=user_id,
                user_timezone=user_timezone,
            )

            graph = self._create_graph()
            final_result = graph.invoke(initial_state)

            return final_result

        except Exception as e:
            import traceback

            traceback.print_exc()
            return f"ì—ëŸ¬ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

    def visualize_graph(self, output_path="graph_visualization.png"):
        """ê·¸ë˜í”„ë¥¼ ì‹œê°í™”í•˜ê³  íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.

        Args:
            output_path (str): ì €ì¥í•  íŒŒì¼ ê²½ë¡œ

        Returns:
            bool: ì„±ê³µ ì—¬ë¶€
        """
        try:
            graph = self._create_graph()

            graph_image = graph.get_graph().draw_mermaid_png()
            with open(output_path, "wb") as f:
                f.write(graph_image)
            print(f"ê·¸ë˜í”„ ì‹œê°í™”ê°€ '{output_path}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            return True
        except Exception as e:
            print(f"ê·¸ë˜í”„ ì‹œê°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return False


def create_agent() -> HealthAnalysisAgent:
    """ê±´ê°• ë¶„ì„ ì—ì´ì „íŠ¸ ìƒì„±

    Args:
        session: SQLAlchemy ì„¸ì…˜

    Returns:
        HealthAnalysisAgent: ì´ˆê¸°í™”ëœ ê±´ê°• ë¶„ì„ ì—ì´ì „íŠ¸
    """
    return HealthAnalysisAgent()
